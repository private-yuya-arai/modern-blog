const r=`---\r
slug: "probability-basics-chapter1"\r
title: "確率論の基礎 完全攻略！ベイズの定理まで"\r
date: "2025-10-01"\r
category: "統計学"\r
tags: ["統計検定準一級", "Python", "R", "確率論", "ベイズの定理"]\r
excerpt: "「条件付き確率」や「ベイズの定理」を直感的に理解する。数式アレルギーでも大丈夫！PythonとRの実装コード付きで、確率の世界を視覚的に学びます。"\r
image: "/images/probability.png"\r
---\r
\r
## この知識はいつ使うの？\r
\r
*   **データから未来を予測したいとき**: 「過去のデータ（条件）」に基づいて「未来の確率」を計算する（天気予報、故障予測）。\r
*   **新しい情報で予測をアップデートしたいとき**: 検査結果が出た後に、病気の確率を再計算する（ベイズ更新）。\r
*   **機械学習モデルの基礎理解**: ナイーブベイズ分類器などのアルゴリズムの仕組みを知りたいとき。\r
\r
## 全体像：確率の世界地図\r
\r
確率には大きく分けて2つの考え方があります。どちらも重要ですが、現代のデータサイエンスでは特に「条件付き確率（ベイズ）」の考え方が重要になります。\r
\r
\`\`\`mermaid\r
graph TD\r
    A["データの海"] --> B{"どう捉える？"}\r
    B -->|頻度論| C["客観的な頻度"]\r
    B -->|ベイズ論| D["主観的な確信度"]\r
    C --> E["サイコロを無限回振る"]\r
    D --> F["新しい情報で確率を更新"]\r
    F --> G["ベイズの定理"]\r
\`\`\`\r
\r
## 1. パターンで理解する「条件付き確率」\r
\r
「ある条件 $B$ が起こった世界において、事象 $A$ が起こる確率」を考えます。\r
全体を見るのではなく、**条件 $B$ というフィルターを通した世界**だけを見るのがポイントです。\r
\r
$$ P(A|B) = \\frac{P(A \\cap B)}{P(B)} $$\r
\r
### 具体例：サイコロの目\r
\r
| パターン | 条件 ($B$) | ターゲット ($A$) | 考え方 | 確率 |\r
| :--- | :--- | :--- | :--- | :--- |\r
| **全体** | なし (全6通り) | 偶数が出る | $\\{2, 4, 6\\}$ の3通り | $3/6 = 50\\%$ |\r
| **条件付き** | **4以上が出る** ($4,5,6$) | 偶数が出る | 条件下で偶数は $\\{4, 6\\}$ の2通り | $2/3 \\approx 66.6\\%$ |\r
\r
条件（フィルター）がかかることで、分母が小さくなり、確率が変わる様子がわかります。\r
\r
## 2. 確率の更新：ベイズの定理\r
\r
条件付き確率の公式を変形すると、**ベイズの定理**が得られます。\r
これは「結果から原因を推測する」ための最強のツールです。\r
\r
$$ P(B|A) = \\frac{P(A|B)P(B)}{P(A)} $$\r
\r
### 理解のためのフローチャート\r
\r
\`\`\`mermaid\r
sequenceDiagram\r
    participant Prior as 事前確率 P(B)\r
    participant Data as データ観測 (A)\r
    participant Posterior as 事後確率 P(B|A)\r
    \r
    Note over Prior: 「病気である確率は1%」<br>(何も知らない状態)\r
    Prior->>Data: データ観測\r
    Note over Data: 「検査で陽性が出た！」<br>(新しい情報)\r
    Data->>Posterior: 確率を更新\r
    Note over Posterior: 「病気である確率は8.7%！」\r
\`\`\`\r
\r
*   **事前確率**: データを見る前の確率（例：一般的に病気にかかっている確率）。\r
*   **尤度（ゆうど）**: 原因 $B$ があったときに、結果 $A$ が出る確率（例：病気の人が陽性になる確率）。\r
*   **事後確率**: 結果 $A$ を知った後の、原因 $B$ の確率（例：陽性だった人が、本当に病気である確率）。\r
\r
## Pythonでの実装：シミュレーションで確認\r
\r
「偶数が出た（条件B）」ときに「4以上（事象A）」である確率を、数式を使わずにシミュレーション（10万回サイコロを振る）で求めてみましょう。\r
\r
\`\`\`python\r
import numpy as np\r
\r
# 1. 10万回の実験\r
N = 100000\r
dice = np.random.randint(1, 7, N)\r
\r
# 2. 条件B: 偶数が出る\r
condition_B = (dice % 2 == 0)\r
\r
# 3. 条件Bを満たすデータだけを抽出（フィルタリング）\r
subset_B = dice[condition_B]\r
\r
# 4. その中で事象A(4以上)が起きている割合を計算\r
prob_A_given_B = np.mean(subset_B >= 4)\r
\r
print(f"条件付き確率（シミュレーション）: {prob_A_given_B:.4f}")\r
# 理論値 2/3 ≈ 0.6666 に近くなるはず\r
\`\`\`\r
\r
## Rでの実装：ベイズ更新の計算\r
\r
検査薬の例（感度95%、特異度90%、有病率1%）を計算してみます。直感に反する結果を確認しましょう。\r
\r
\`\`\`r\r
# パラメータ設定\r
prior <- 0.01          # 事前確率 P(病気)\r
sensitivity <- 0.95    # 感度 P(陽性|病気)\r
specificity <- 0.90    # 特異度 P(陰性|健康)\r
\r
# 全確率の公式で P(陽性) を計算 (分母)\r
# P(陽性) = P(陽性|病気)P(病気) + P(陽性|健康)P(健康)\r
prob_positive <- (sensitivity * prior) + ((1 - specificity) * (1 - prior))\r
\r
# ベイズの定理で事後確率 P(病気|陽性) を計算\r
posterior <- (sensitivity * prior) / prob_positive\r
\r
cat(sprintf("検査陽性の人の実際の有病率: %.1f%%", posterior * 100))\r
\`\`\`\r
\r
## まとめ\r
\r
*   **条件付き確率は「フィルタリング」**: 全体を見るのではなく、特定の条件下の世界を見る。\r
*   **ベイズの定理は「学習」**: 新しい情報（データ）を得るたびに、認識（確率）をアップデートしていくプロセス。\r
*   **直感は当てにならない**: 特に「偽陽性」の問題など、計算してみると直感とズレることが多いので注意が必要。\r
`;export{r as default};
